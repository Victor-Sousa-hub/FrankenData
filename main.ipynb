{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### Criando banco de dados"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sqlite3\n","\n","conn = sqlite3.connect('stackoverflow.db')\n","cursor = conn.cursor()\n","\n","cursor.execute('''\n","CREATE TABLE IF NOT EXISTS questions(\n","    id INTERGER PRIMARY KEY,\n","    title TEXT,\n","    tag TEXT,\n","    body TEXT \n",")\n","''')\n","\n","conn.commit()\n","print('Banco de dados criado com sucesso')"]},{"cell_type":"markdown","metadata":{},"source":["#### Função que adiciona os dados a base"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def save_question(questions,tag):\n","    for question in questions:\n","        cursor.execute(''' INSERT OR REPLACE INTO questions (id,title,tag,body) VALUES (?,?,?,?) ''',\n","            (question['question_id'],question['title'],tag,question['body']))\n","    conn.commit()\n","    print(f'Tema {question} salvo na base')\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tema {'question_id': 78990048, 'title': 'Make borders in dataframe pandas', 'body': '<p>How to make borders in dataframe in each cell:\\n<img src=\"https://i.sstatic.net/XIPAjA0c.png\" alt=\"enter image description here\" /></p>\\n<p>For example I have got the following dataframe:</p>\\n<pre><code>import pandas as pd\\n\\ndf = pd.DataFrame({\\'planet\\': [\\'Earth\\', \\'Moon\\', \\'Mars\\'], \\'mass_to_earth\\': [1, 0.606, 0.107]})\\n\\ndf\\n</code></pre>\\n<p>And I need to get bold (and not) borders in this table in each cell. How can I do this?</p>\\n'} salvo na base\n","Tema {'question_id': 78954080, 'title': 'How to interpret the look_ahead_mask when training a generative transformer in tensorflow (2.10.1)?', 'body': '<p>I\\'m trying to implement a training loop for a transformer, using an encoder/decoder pair. Based on my understanding of how transformers work, I was expecting that to generate my output sequence, I would have to iterate the decoder, feeding its output back as input on each step, and building up my output sequence one token at a time.</p>\\n<p>Following the notation used in the tensorflow documentation, assume the output sequence has dimension <code>(B, T, dim)</code>, where <code>B</code> is the batch size, <code>T</code> is the target/output sequence length and <code>dim</code> is the size of the target/output embedding vector.</p>\\n<p>So to generate the complete output sequence, I would have to iterate the decoder <code>T</code> times. To prevent the decoder\\'s self-attention mechanism from attending to tokens ahead of the current step <code>t</code>, I have to mask all sequence tokens from position <code>t+1</code> onwards.</p>\\n<p>For example:</p>\\n<pre><code>T = 4\\ngenerate token at position 0: look_ahead_mask = [0, 0, 0, 0].T\\ngenerate token at position 1: look_ahead_mask = [1, 0, 0, 0].T\\ngenerate token at position 2: look_ahead_mask = [1, 1, 0, 0].T\\ngenerate token at position 3: look_ahead_mask = [1, 1, 1, 0].T\\n</code></pre>\\n<p>My confusion comes when looking at how the MultiHeadAttention layer implements the look-ahead mask. From online examples (e.g. <a href=\"https://machinelearningmastery.com/joining-the-transformer-encoder-and-decoder-and-masking/\" rel=\"nofollow noreferrer\">Jason Brownlee\\'s blog</a>), the mask is passed as an array with dimensions <code>(T, T)</code>, and seems to represent all <code>T</code> masks that would be needed if generating the output sequence one token at a time.</p>\\n<p>For example:</p>\\n<pre><code>T = 4\\nlook_ahead_mask = [[0, 1, 1, 1]\\n                   [0, 0, 1, 1]\\n                   [0, 0, 0, 1]\\n                   [0, 0, 0, 0]]\\n</code></pre>\\n<p>Does this mean that a single call to the decoder is internally looping through the entire output sequence? And if this is the case, how does it know when to stop generating any given sequence in the batch when an <code>EOS</code> token is generated? Do I not then need to manually loop over tokens in the output sequence?</p>\\n'} salvo na base\n","Tema {'question_id': 78943962, 'title': 'Low FPS and lot of delay with my pytorch model', 'body': \"<p>I have a task to process a streaming video from a Hikvision IP camera using OpenCV. Initially, the video’s FPS is around 20-25 with a 2-3 second delay. However, as the code runs for a longer period, the FPS quickly drops and the delay increases. Eventually, the FPS drops to 2-3, and the video freezes.</p>\\n<pre><code>class VideoLoader:\\n    @staticmethod\\n    def load_video(video_path):\\n        cap = cv2.VideoCapture(video_path)\\n        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\\n        cap.set(cv2.CAP_PROP_FPS, 25)\\n        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\\n        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  \\n        assert cap.isOpened(), &quot;Video dosyası okunurken hata oluştu&quot;\\n        return cap\\n</code></pre>\\n<p>I have tried methods such as using the GPU, employing multithreading, and reducing the resolution, but these haven't been very effective. What do you think is the problem and how can I solve it</p>\\n<pre><code>def frame_reader(cap, frame_queue):\\n    while cap.isOpened():\\n        success, frame = cap.read()\\n        if not success:\\n            break\\n        if not frame_queue.full():  # Check if the queue has space\\n            frame_queue.put(frame)\\n    cap.release()\\n    frame_queue.put(None)  # End-of-stream signal\\n\\ndef video_processor(frame_queue, output_queue, model, class_names, played_sounds):\\n    threshold = 0.5  # Tespit eşik değeri\\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n    model.to(device)\\n\\n    while True:\\n        frame = frame_queue.get()\\n        if frame is None:  # End-of-stream signal\\n            break\\n        start_time = time.time()\\n        img = cv2.resize(frame, (640, 480))\\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n        img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float().unsqueeze(0).to(device)\\n        img_tensor /= 255.0  # Normalize\\n\\ndef video_detection(video_source):\\n    cap = VideoLoader.load_video(video_source)\\n    model = YOLO(&quot;YOLO-Weights/ppe.pt&quot;)\\n    class_names = ['safety-glasses', 'gloves', 'orange-vest', 'yellow-vest',]\\n    played_sounds = set()\\n\\n    frame_queue = Queue(maxsize=5)\\n    output_queue = Queue(maxsize=5)\\n\\n    reader_thread = threading.Thread(target=frame_reader, args=(cap, frame_queue), daemon=True)\\n    processor_thread = threading.Thread(target=video_processor, args=(frame_queue,output_queue, model,class_names, played_sounds), daemon=True)\\n\\n    reader_thread.start()\\n    processor_thread.start()\\n</code></pre>\\n\"} salvo na base\n","Tema {'question_id': 78984081, 'title': 'Multiple random selection from MultiIndex', 'body': \"<p>Consider the following DataFrame:</p>\\n<pre><code>import pandas as pd\\narrays = [['A','A','B','B','C','C'],[1,1,3,3,5,5,],[2,2,4,4,6,6],[0.1,0.2,0.3,0.4,0.5,0.6]]\\nindex = pd.MultiIndex.from_arrays(arrays,names=('Sample','P1','P2','T'))\\ndata = np.random.rand(10,6)\\ndf = pd.DataFrame(columns=index,data=data)\\n</code></pre>\\n<p>I want to select: for sample A, the column with T=0.2, and for sample C, the column with T=0.5.</p>\\n<p>I can easily select each of the single columns, e.g.:</p>\\n<pre><code>df.loc[:,('A',slice(None),slice(None),0.2)]  # or\\ndf.loc(axis=1)[('C',slice(None),slice(None),0.5)] \\n</code></pre>\\n<p>But how can I combine them? I tried supplying a list of tuples:</p>\\n<pre><code>df.loc[:,[('A',slice(None),slice(None),0.2),('C',slice(None),slice(None),0.5)]]\\n</code></pre>\\n<p>But that generates an error.</p>\\n<p>How can I select my columns without resorting to <code>pd.concat</code>?</p>\\n\"} salvo na base\n","Tema {'question_id': 40780033, 'title': 'ValueError: The number of classes has to be greater than one (python)', 'body': '<p>When passing <code>x,y</code> in <code>fit</code>, I am getting the following error:</p>\\n\\n<p>Traceback (most recent call last):</p>\\n\\n<blockquote>\\n  <p>File \"C:/Classify/classifier.py\", line 95, in </p>\\n  \\n  <p>train_avg, test_avg, cms = train_model(X, y, \"ceps\", plot=True)<br>\\n  File \"C:/Classify/classifier.py\", line 47, in train_model</p>\\n  \\n  <p>clf.fit(X_train, y_train)   File \"C:\\\\Python27\\\\lib\\\\site-packages\\\\sklearn\\\\svm\\\\base.py\", line 676, in fit\\n  raise ValueError(\"The number of classes has to be greater than\" ValueError: The number of classes has to be greater than one.</p>\\n</blockquote>\\n\\n<p>Below is my code:</p>\\n\\n<pre><code>def train_model(X, Y, name, plot=False):\\n\"\"\"\\n    train_model(vector, vector, name[, plot=False])\\n\\n    Trains and saves model to disk.\\n\"\"\"\\nlabels = np.unique(Y)\\n\\ncv = ShuffleSplit(n=len(X), n_iter=1, test_size=0.3, indices=True, random_state=0)\\n\\ntrain_errors = []\\ntest_errors = []\\n\\nscores = []\\npr_scores = defaultdict(list)\\nprecisions, recalls, thresholds = defaultdict(list), defaultdict(list), defaultdict(list)\\n\\nroc_scores = defaultdict(list)\\ntprs = defaultdict(list)\\nfprs = defaultdict(list)\\n\\nclfs = []  # for the median\\n\\ncms = []\\n\\nfor train, test in cv:\\n    X_train, y_train = X[train], Y[train]\\n    X_test, y_test = X[test], Y[test]\\n\\n    clf = LogisticRegression()\\n    clf.fit(X_train, y_train)\\n    clfs.append(clf)\\n</code></pre>\\n'} salvo na base\n","Tema {'question_id': 78812664, 'title': 'R Package for Displaying Two-Way ANOVA with Mean, SE, and Significance Letters (Both Capital and Small Letters)', 'body': '<p>I am looking for an R package that can help me display the results of a two-way ANOVA. Specifically, I need to include the following elements in my output:</p>\\n<p>Mean values ( not estimated, originial)\\nStandard Errors (SE) ( not estimated, originial)\\nSignificance indicated with letters, using both capital and small letters (e.g., \\'A\\', \\'a\\', \\'B\\', \\'b\\')</p>\\n<p>fit &lt;- aov(log(response) ~ treatments(4 levels) * species(4 types), data = sample_data)\\ntukeyHSD(fit)</p>\\n<p>the table should look like\\n<a href=\"https://i.sstatic.net/zKLYv45n.jpg\" rel=\"nofollow noreferrer\">enter image description here</a></p>\\n<p>The capital letters are comparing species column wise and small letters comparing treatments.\\nIs there an R package that provides this functionality, or any combination of functions/packages that can help me achieve this? The interaction is non significant so interactions should be removed?</p>\\n<p>Emmeans gives only estimated mean, MultcompView only gives small letters (may be I am wrong) and the final table is too many letters.</p>\\n'} salvo na base\n"]}],"source":["import httpx\n","\n","\n","url = \"https://api.stackexchange.com/2.3/questions\"\n","site = \"stackoverflow\"\n","api_key = \"rl_sVA4bTddeGTtj2EFpzt2RKu7r\"\n","page_size = 100\n","max_page = 5\n","assuntos = ['pandas','tensorflow','machine-learning','dataframe','scikit-learn',\n","            'data-visualization']\n","\n","def get_stackoverflow_questions(tag, page):\n","    params = {\n","        \"order\": \"desc\",\n","        \"sort\": \"activity\",\n","        \"tagged\": tag,\n","        \"site\": site,\n","        \"page\": page,\n","        \"filter\" : \"withbody\",\n","        \"page_size\" : page_size,\n","        \"key\" : api_key,\n","        \"is_answered\" : 'True'\n","    }\n","    response = httpx.get(url, params=params)\n","    response.raise_for_status()  # Levanta um erro se a requisição falhar\n","    return response.json()\n","\n","# Exemplo de uso\n","\n","base = {\n","    'pandas' : [],\n","    'tensorflow': [],\n","    'machine-learning': [],\n","    'dataframe' : [],\n","    'scikit-learn' : [],\n","    'data-visualization' : []\n","}\n","\n","for assunto in assuntos:\n","  for i in range(1,max_page+1):\n","      question = get_stackoverflow_questions(assunto, i)\n","      for item in question['items']:\n","        body ={\n","          'question_id' : item['question_id'],\n","          'title' : item['title'],\n","          'body' :  item['body']\n","        }\n","        base[assunto].append(body)\n","\n","\n","for tema in base:\n","    save_question(base[tema],tema)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
